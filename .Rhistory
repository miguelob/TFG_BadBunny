str(data_dm)
#Normalization of variables
data_norm_or<-normalizeData(data_dm, type="0_1" )
library(arules)
library(arulesViz)
library(tidyverse)
library(readxl)
library(knitr)
library(ggplot2)
library(lubridate)
library(plyr)
library(dplyr)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(dummies)  #for creration of dummy variables
library(caret)     #for confusion matrix
library(RSNNS)     #for normalization
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
summary(data)
### ============ CLUSTERING ==============
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:9], min_max_norm))
data_norm$total_bedrooms <- NULL
data_norm<- as.data.frame(lapply(data[3:13], min_max_norm))
data_norm$total_bedrooms <- NULL
data_norm$Track <- NULL
data_norm<- as.data.frame(lapply(data[3:13], min_max_norm))
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
summary(data)
### ============ CLUSTERING ==============
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[3:13], min_max_norm))
set.seed(3141592)
index <- sample(nrow(data_norm), round(0.75*nrow(data_norm)))
train <- data_norm[index,]
test <- data_norm[-index,]
train_label<- data[index,1]
test_label<- data[-index,1]
#Optimum number of clusters. Elbow method
# Alternative using fviz function for Elbow method
#set.seed(123)
fviz_nbclust(train, hcut, method = "wss", k.max = 20)
fviz_nbclust(train, hcut, method = "silhouette")
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
data$Track <-- NULL
set.seed(3141592)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
summary(data)
### ============ CLUSTERING ==============
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
data$Track <-- NULL
data$Track <-- NULL
data$Track <- NULL
set.seed(3141592)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
summary(data)
### ============ CLUSTERING ==============
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[2:13], min_max_norm))
set.seed(3141592)
data_norm<- as.data.frame(lapply(data[2:12], min_max_norm))
set.seed(3141592)
index <- sample(nrow(data_norm), round(0.75*nrow(data_norm)))
train <- data_norm[index,]
test <- data_norm[-index,]
train_label<- data[index,1]
test_label<- data[-index,1]
#Optimum number of clusters. Elbow method
# Alternative using fviz function for Elbow method
#set.seed(123)
fviz_nbclust(train, hcut, method = "wss", k.max = 20)
#Optimum number of clusters. Elbow method
# Alternative using fviz function for Elbow method
#set.seed(123)
fviz_nbclust(train, hcut, method = "wss", k.max = 20)
fviz_nbclust(train, hcut, method = "silhouette")
gap_stat <- clusGap(train, FUN = hcut, nstart = 25,
K.max = 15, B = 25)
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
#Clustering using HC
# computing distance matrix between the rows of the data matrix
distance <- dist(train,method = "euclidean")
# Visualization of a distance matrix
fviz_dist(distance, gradient = list(low = "#00AFBB",
mid = "white", high = "#FC4E07"))
# Hierarchical clustering using COMPLETE LINKAGE
hc_CL<-hclust(distance, method="complete")
# Plot the obtained dendrogram
plot(hc_CL, cex=0.6, hang=-1)
# similar estimation using agnes
hc_CL_agnes<-agnes(data, method = "complete")
#Agglomerative coefficient
hc_CL_agnes$ac
# Plot the obtained dendrogram
pltree(hc_CL_agnes, cex=0.6, hang=-1)
# Comparing different HC methods
# methods to assess
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
# function to compute coefficient
ac <- function(x) {
agnes(train, method = x)$ac
}
map_dbl(m, ac)
#Using the ward method as identified in this case as better
hc_CL_Ward <- agnes(train, method = "ward")
pltree(hc_CL_Ward, cex = 0.6, hang = -1, main = "Dendrogram of agnes - Ward")
# Sub-Groups identification
# Ward's method
hc_sg <- hclust(distance, method = "ward.D2" )
# Cut tree into 7 groups
sub_grp <- cutree(hc_sg, k = 7)
# Number of members in each cluster
table(sub_grp)
######## Analysis of clusters
confusionMatrix(as.factor(train_label), as.factor(assoc$cluster))
#Plotting sub-groups with colors
plot(hc_sg, cex = 0.6)
rect.hclust(hc_sg, k = 7, border = 2:5)
fviz_cluster(list(data = train, cluster = sub_grp),
choose.vars = c("median_house_value", "total_rooms") )
library(tidyverse)      #data manipulation and visualization
library(class)          # to call class package for kNN
library(caret)          # for building the model
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(dummies)  #for creration of dummy variables
library(caret)     #for confusion matrix
library(RSNNS)     #for normalization
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
data$Track <- NULL
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
data_norm_or<-normalizeData(data, type="0_1" )
param<-getNormParameters(data_norm_or)
#conversion to data frame
data.n<- as.data.frame(data_norm_or)
colnames(data.n)<- colnames(data)
library(tidyverse)      #data manipulation and visualization
library(class)          # to call class package for kNN
library(caret)          # for building the model
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(dummies)  #for creration of dummy variables
library(caret)     #for confusion matrix
library(RSNNS)     #for normalization
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
data_norm_or<-normalizeData(data, type="0_1" )
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[2:12], min_max_norm))
View(data_norm)
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
data_norm<- as.data.frame(lapply(data[2:12], min_max_norm))
data_norm$Album <- data$Album
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
library(tidyverse)      #data manipulation and visualization
library(class)          # to call class package for kNN
library(caret)          # for building the model
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(dummies)  #for creration of dummy variables
library(caret)     #for confusion matrix
library(RSNNS)     #for normalization
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[2:12], min_max_norm))
data_norm$Album <- data$Album
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=3,nstart=20)
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
data$Album <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
index <- sample(nrow(data), round(0.1*nrow(data)))
data <- data[index,]
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
data_norm$Album <- data$Album
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#GAP method
# compute gap statistic
#set.seed(123)
gap_stat <- clusGap(data.n, FUN = kmeans, nstart = 25,
K.max = 15, B = 25)
# Print the result
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=3,nstart=20)
# clustering results
str(cluster6)
cluster6
cluster6$size
#visualization  of clusters
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("total_rooms","median_house_value")]))
#denormalizing centers to obtain real values
codes<- cluster6$centers
denorm_codes<- denormalizeData(codes, getNormParameters(data_norm_or))
assigned_cluster <- cluster6$cluster
data.n$assigned_cluster<- cluster6$cluster
data$assigned_cluster<- cluster6$cluster
denorm_codes
#denormalizing centers to obtain real values
codes<- cluster6$centers
View(codes)
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("Valence","Energy")]),stand = FALSE,
ellipse.type = "norm") + theme_bw()
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
data$Album <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
data <- data[index,]
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
data_norm$Album <- data$Album
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#GAP method
# compute gap statistic
#set.seed(123)
gap_stat <- clusGap(data.n, FUN = kmeans, nstart = 25,
K.max = 15, B = 25)
# Print the result
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=3,nstart=20)
# clustering results
str(cluster6)
cluster6
cluster6$size
#visualization  of clusters
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("total_rooms","median_house_value")]))
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("Valence","Energy")]),stand = FALSE,
ellipse.type = "norm") + theme_bw()
#denormalizing centers to obtain real values
codes<- cluster6$centers
library(tidyverse)      #data manipulation and visualization
library(class)          # to call class package for kNN
library(caret)          # for building the model
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(dummies)  #for creration of dummy variables
library(caret)     #for confusion matrix
library(RSNNS)     #for normalization
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
data$Album <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
data_norm$Album <- data$Album
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#GAP method
# compute gap statistic
#set.seed(123)
gap_stat <- clusGap(data.n, FUN = kmeans, nstart = 25,
K.max = 15, B = 25)
# Print the result
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=3,nstart=20)
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#GAP method
# compute gap statistic
#set.seed(123)
gap_stat <- clusGap(data.n, FUN = kmeans, nstart = 25,
K.max = 15, B = 25)
# Print the result
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
data<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
set.seed(3141592)
data$Track <- NULL
#data$Album <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
#conversion to data frame
data.n<- as.data.frame(data_norm)
data$Album <- NULL
#index <- sample(nrow(data), round(0.1*nrow(data)))
#data <- data[index,]
summary(data)
data<-na.omit(data)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
data_norm<- as.data.frame(lapply(data[1:11], min_max_norm))
#conversion to data frame
data.n<- as.data.frame(data_norm)
colnames(data.n)<- colnames(data)
#transposing the data matrix for getting distances of variables (products)
tdata<-t(data.n)
# data structure where all the varaibles are integers including
#'Creditability' which is the response variable for this example.
str(data)
#removing any missing value
fviz_nbclust(data.n, kmeans, method = "wss", k.max = 20)
#Optimum number of clusters. Silhouette method
# function to compute average silhouette for k clusters
#set.seed(123)
fviz_nbclust(data.n, kmeans, method = "silhouette")
#GAP method
# compute gap statistic
#set.seed(123)
gap_stat <- clusGap(data.n, FUN = kmeans, nstart = 25,
K.max = 15, B = 25)
# Print the result
print(gap_stat, method = "firstmax")
# Alternative using the fviz_gap_stat function
fviz_gap_stat(gap_stat)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=3,nstart=20)
########## 5 clusters one per type of wine
cluster6<-kmeans(data.n,centers=9,nstart=20)
# clustering results
str(cluster6)
cluster6
cluster6$size
#visualization  of clusters
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("Valence","Energy")]))
#visualization  of clusters
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("Acusticness","Energy")]))
#visualization  of clusters
fviz_cluster(cluster6, data=data.n,
choose.vars = colnames(data.n[, c("Acousticness","Energy")]))
#denormalizing centers to obtain real values
codes<- cluster6$centers
assigned_cluster <- cluster6$cluster
data.n$assigned_cluster<- cluster6$cluster
data$assigned_cluster<- cluster6$cluster
data.n$Album <- datos$Album
datos<-read.csv('discografia.csv',sep=',',stringsAsFactors=T)
data.n$Album <- datos$Album
View(data.n)
